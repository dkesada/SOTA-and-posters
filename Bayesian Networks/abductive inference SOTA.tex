\documentclass[a4paper,11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[dvipdfmx]{graphicx}
\usepackage{graphics,latexsym}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage[dvips]{color}
\usepackage{subfigure}
\usepackage{verbatim}

\bibpunct{(}{)}{;}{a}{,}{,}

\textheight 24cm \textwidth 17cm \topmargin-2cm
%% \evensidemargin   -0.25cm
\oddsidemargin-0.2cm
%\pagestyle{empty}
\renewcommand{\baselinestretch}{1}

\begin{document}

\title{Abductive inference in bayesian networks}

\author{{David Quesada López}\\
{\small Computational Intelligence Group, Departamento de Inteligencia Artificial, Universidad Polit\'ecnica de Madrid, Spain}}

\date{}
\maketitle

%\title{}

%\address{}

\begin{abstract} Abductive inference in bayesian networks solves the problem of obtaining the most probable explanation (MPE) of a network given some evidence of its nodes. This inference can be total, if you aim to obtain the MPE of the whole network, or partial, if you are only interested in some of the nodes. In this state of the art we will cover both approaches and the methods used to solve them.
\end{abstract}


\ \\
KEY WORDS: Bayesian networks; Abductive inference; Approximate inference


\section{Introduction}

A Bayesian network is a directed acyclic graph (DAG) where you represent each node as a random variable and the edges represent the dependence or independence among them. Each node also has associated a conditional probability distribution conditioned to its parents that represents the probability distribution of the node's variable.

One of the problems associated with BNs is abductive inference, which consists in finding the maximum \textit{a posteriori} probability (MAP) state of the network given some evidence on the state of variables of the network. In general, we are interested in the \textit{K} most probable explanations (k-MPE). This problem is known to be NP-hard (\cite{shimony1994}), and most of the times trying to obtain an exact MPE turns out to be intractable. This is the reason why most researchers focus on getting \textit{K} approximate MPEs instead of the exact one. 

% formula MPE?

Abductive inference can also be called total, when we want to know the whole network's k-MPE, or partial, when we only want the \textit{K} most probable state assignments for a subset of the variables known as the explanation set 
(\cite{fortier2013}).

In this state of the art, we will review some methods to perform total and partial abductive inference on a Bayesian network.

\section{State-of-the-art}



\subsection{Total abductive inference}

\subsection{Partial abductive inference}



\section{Conclusions and future research}

What are the main open lines for research.



\bibliographystyle{plainnat}
\begin{thebibliography}{}

\bibitem[De Campos \textit{et al.}, 1999]{deCampos1999}
De Campos L. M., Gámez J. A., Moral S. (1999). Partial abductive inference in Bayesian belief networks using a genetic algorithm. Pattern Recognition Letters, 20(11), 1211-1217.

\bibitem[De Campos \textit{et al.}, 2002]{deCampos2002}
De Campos L. M., Gamez J. A., Moral S. (2002). Partial abductive inference in Bayesian belief networks-an evolutionary computation approach by using problem-specific genetic operators. IEEE Transactions on Evolutionary Computation, 6(2), 105-131.

\bibitem[Fortier \textit{et al.}, 2013]{fortier2013}
Fortier N., Sheppard J., Pillai K. G. (2013, April). Bayesian abductive inference using overlapping swarm intelligence. In Swarm Intelligence (SIS), 2013 IEEE Symposium on (pp. 263-270). IEEE.

\bibitem[Gelsema, 1995]{gelsema1995}
Gelsema E. S. (1995). Abductive reasoning in Bayesian belief networks using a genetic algorithm. Pattern Recognition Letters, 16(8), 865-871.

\bibitem[Shimony, 1994]{shimony1994}
Shimony S. (1994). Finding maps for belief networks is NP-hard. Artificial Intelligence 68, 399-410.

\end{thebibliography}


\end{document}
